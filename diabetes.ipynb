{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Diabetes prediction\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pima Indians Diabetes Database\n",
    "#Predict the onset of diabetes based on diagnostic measures\n",
    "#UCI Machine Learning\n",
    "#The Applied options are for CSV files\n",
    "df = spark.read.format(\"csv\") \\\n",
    "     .option(\"inferSchema\",\"true\") \\\n",
    "     .option(\"header\",\"true\") \\\n",
    "     .option(\"sep\",\",\") \\\n",
    "     .load(\"datasets/ds_diabetes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1),\n",
       " Row(Pregnancies=1, Glucose=85, BloodPressure=66, SkinThickness=29, Insulin=0, BMI=26.6, DiabetesPedigreeFunction=0.351, Age=31, Outcome=0),\n",
       " Row(Pregnancies=8, Glucose=183, BloodPressure=64, SkinThickness=0, Insulin=0, BMI=23.3, DiabetesPedigreeFunction=0.672, Age=32, Outcome=1),\n",
       " Row(Pregnancies=1, Glucose=89, BloodPressure=66, SkinThickness=23, Insulin=94, BMI=28.1, DiabetesPedigreeFunction=0.167, Age=21, Outcome=0),\n",
       " Row(Pregnancies=0, Glucose=137, BloodPressure=40, SkinThickness=35, Insulin=168, BMI=43.1, DiabetesPedigreeFunction=2.288, Age=33, Outcome=1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "data_types = defaultdict(list)\n",
    "for entry in df.schema.fields:\n",
    "  data_types[str(entry.dataType)].append(entry.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'IntegerType': ['Pregnancies',\n",
       "              'Glucose',\n",
       "              'BloodPressure',\n",
       "              'SkinThickness',\n",
       "              'Insulin',\n",
       "              'Age',\n",
       "              'Outcome'],\n",
       "             'DoubleType': ['BMI', 'DiabetesPedigreeFunction']})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Pregnancies: int, Glucose: int, BloodPressure: int, SkinThickness: int, Insulin: int, BMI: double, DiabetesPedigreeFunction: double, Age: int, Outcome: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimension: ( 768 , 9 )\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset dimension: (\",df.count(),\",\",len(df.columns),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Outcome: int, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "display(df.groupby('Outcome').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_used = [\"Pregnancies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referencia Hien Luu - Beginning Apache Spark 2_ With Resilient Distributed Datasets, Spark SQL, Structured Streaming and Spark Machine Learning library-Apress (2018)\n",
    "\"\"\"\n",
    "The OneHotEncoder transformer is commonly used when working with numeric\n",
    "categorical values. If the categorical values are of string type, then first apply the\n",
    "StringIndexer estimator to convert them to a numerical type. The OneHotEncoder\n",
    "transformer essentially maps a numeric categorical value into a binary vector to\n",
    "purposely remove the implicit ranking of the numeric categorical values.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Estimator: StringIndexer\n",
    "Data Transformation algorithms\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_string = [StringIndexer(inputCol= c, outputCol = c+\"_string_encoded\") for c in strings_used]\n",
    "stage_one_hot = [OneHotEncoder(inputCol= c+\"_string_encoded\",outputCol= c+ \"_one_hot\") for c in strings_used]\n",
    "ppl = Pipeline(stages= stage_string + stage_one_hot)\n",
    "df = ppl.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1, Pregnancies_string_encoded=6.0, Pregnancies_one_hot=SparseVector(16, {6: 1.0})),\n",
       " Row(Pregnancies=1, Glucose=85, BloodPressure=66, SkinThickness=29, Insulin=0, BMI=26.6, DiabetesPedigreeFunction=0.351, Age=31, Outcome=0, Pregnancies_string_encoded=0.0, Pregnancies_one_hot=SparseVector(16, {0: 1.0})),\n",
       " Row(Pregnancies=8, Glucose=183, BloodPressure=64, SkinThickness=0, Insulin=0, BMI=23.3, DiabetesPedigreeFunction=0.672, Age=32, Outcome=1, Pregnancies_string_encoded=8.0, Pregnancies_one_hot=SparseVector(16, {8: 1.0})),\n",
       " Row(Pregnancies=1, Glucose=89, BloodPressure=66, SkinThickness=23, Insulin=94, BMI=28.1, DiabetesPedigreeFunction=0.167, Age=21, Outcome=0, Pregnancies_string_encoded=0.0, Pregnancies_one_hot=SparseVector(16, {0: 1.0})),\n",
       " Row(Pregnancies=0, Glucose=137, BloodPressure=40, SkinThickness=35, Insulin=168, BMI=43.1, DiabetesPedigreeFunction=2.288, Age=33, Outcome=1, Pregnancies_string_encoded=1.0, Pregnancies_one_hot=SparseVector(16, {1: 1.0}))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referencia Hien Luu - Beginning Apache Spark 2_ With Resilient Distributed Datasets, Spark SQL, Structured Streaming and Spark Machine Learning library-Apress (2018)\n",
    "#Transformer: VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "features = ['Pregnancies_one_hot','Glucose','BloodPressure',\n",
    "'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "vector_assembler = VectorAssembler(inputCols = features, outputCol= \"features\")\n",
    "data_training_and_test = vector_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.80255828347421\n"
     ]
    }
   ],
   "source": [
    "#Etapa de entrenamiento\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "(training_data, test_data) = data_training_and_test.randomSplit([0.7, 0.3], 2017)\n",
    "rf = RandomForestClassifier(labelCol = \"Outcome\", \n",
    "                        featuresCol = \"features\", numTrees = 20)\n",
    "rf_model = rf.fit(training_data)\n",
    "predictions = rf_model.transform(test_data)\n",
    "evaluator= BinaryClassificationEvaluator(labelCol = \"Outcome\", rawPredictionCol=\"probability\", metricName= \"areaUnderROC\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "importance_list = pd.Series(rf_model.featureImportances.values)\n",
    "sorted_imp = importance_list.sort_values(ascending= False)\n",
    "kept = list((sorted_imp[sorted_imp > 0.03]).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  81.63296884670925\n"
     ]
    }
   ],
   "source": [
    "#Etapa de Test\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "vector_slicer = VectorSlicer(inputCol= \"features\", indices= kept, outputCol= \"feature_subset\")\n",
    "with_selected_feature = vector_slicer.transform(training_data)\n",
    "rf_modified = RandomForestClassifier(numTrees=20, labelCol = \"Outcome\", featuresCol=\"feature_subset\")\n",
    "test_data = vector_slicer.transform(test_data)\n",
    "prediction_modified = rf_modified.fit(with_selected_feature).transform(test_data)\n",
    "evaluator_modified = BinaryClassificationEvaluator(labelCol = \"Outcome\",rawPredictionCol=\"probability\", metricName= \"areaUnderROC\")\n",
    "accuracy = evaluator_modified.evaluate(prediction_modified)\n",
    "print(\"Accuracy: \",accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
